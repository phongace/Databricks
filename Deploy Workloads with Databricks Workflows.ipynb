{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"metadata\": {\n",
    "    \"application/vnd.databricks.v1+cell\": {\n",
    "     \"cellMetadata\": {},\n",
    "     \"inputWidgets\": {},\n",
    "     \"nuid\": \"ef1abaff-f125-4489-85ec-fbeaa88fdf1b\",\n",
    "     \"showTitle\": false,\n",
    "     \"tableResultSettingsMap\": {},\n",
    "     \"title\": \"\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Databricks notebook source\\n\",\n",
    "    \"import requests\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from datetime import datetime\\n\",\n",
    "    \"\\n\",\n",
    "    \"# API configuration\\n\",\n",
    "    \"CITY = \\\"Hanoi\\\"\\n\",\n",
    "    \"URL = \\\"https://api.open-meteo.com/v1/forecast?latitude=21.0285&longitude=105.8542&current_weather=true\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Fetch data from API\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    response = requests.get(URL)\\n\",\n",
    "    \"    response.raise_for_status()  # Raise exception for HTTP errors\\n\",\n",
    "    \"    data = response.json()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Extract current weather data\\n\",\n",
    "    \"    current_weather = data.get(\\\"current_weather\\\", {})\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create DataFrame with the new API response structure\\n\",\n",
    "    \"    weather_data = {\\n\",\n",
    "    \"        \\\"city\\\": [CITY],\\n\",\n",
    "    \"        \\\"timestamp\\\": [datetime.now().isoformat()],\\n\",\n",
    "    \"        \\\"api_timestamp\\\": [current_weather.get(\\\"time\\\")],\\n\",\n",
    "    \"        \\\"temperature\\\": [current_weather.get(\\\"temperature\\\")],\\n\",\n",
    "    \"        \\\"windspeed\\\": [current_weather.get(\\\"windspeed\\\")],\\n\",\n",
    "    \"        \\\"winddirection\\\": [current_weather.get(\\\"winddirection\\\")],\\n\",\n",
    "    \"        \\\"is_day\\\": [current_weather.get(\\\"is_day\\\")],\\n\",\n",
    "    \"        \\\"weathercode\\\": [current_weather.get(\\\"weathercode\\\")],\\n\",\n",
    "    \"        \\\"latitude\\\": [data.get(\\\"latitude\\\")],\\n\",\n",
    "    \"        \\\"longitude\\\": [data.get(\\\"longitude\\\")],\\n\",\n",
    "    \"        \\\"elevation\\\": [data.get(\\\"elevation\\\")]\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"    df = pd.DataFrame(weather_data)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Save as temporary Delta table\\n\",\n",
    "    \"    spark_df = spark.createDataFrame(df)\\n\",\n",
    "    \"    spark_df.write.mode(\\\"overwrite\\\").saveAsTable(\\\"temp_weather_raw\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    dbutils.notebook.exit(\\\"Successfully fetched weather data for \\\" + CITY)\\n\",\n",
    "    \"\\n\",\n",
    "    \"except requests.exceptions.RequestException as e:\\n\",\n",
    "    \"    dbutils.notebook.exit(f\\\"API request failed: {str(e)}\\\")\\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    dbutils.notebook.exit(f\\\"An error occurred: {str(e)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"metadata\": {\n",
    "    \"application/vnd.databricks.v1+cell\": {\n",
    "     \"cellMetadata\": {},\n",
    "     \"inputWidgets\": {},\n",
    "     \"nuid\": \"845ae0f1-8a0a-40d2-8341-07155b8ecdab\",\n",
    "     \"showTitle\": false,\n",
    "     \"tableResultSettingsMap\": {},\n",
    "     \"title\": \"\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Databricks notebook source\\n\",\n",
    "    \"from pyspark.sql.functions import col, from_unixtime, unix_timestamp, lit\\n\",\n",
    "    \"from pyspark.sql.functions import when\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Read raw data\\n\",\n",
    "    \"raw_df = spark.table(\\\"temp_weather_raw\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Transform data\\n\",\n",
    "    \"transformed_df = raw_df.withColumn(\\n\",\n",
    "    \"    \\\"processed_timestamp\\\", \\n\",\n",
    "    \"    from_unixtime(unix_timestamp(col(\\\"timestamp\\\")))\\n\",\n",
    "    \").withColumn(\\n\",\n",
    "    \"    \\\"weather_condition\\\",\\n\",\n",
    "    \"    # Map WMO weather codes to human-readable descriptions\\n\",\n",
    "    \"    when(col(\\\"weathercode\\\") == 0, \\\"Clear sky\\\")\\n\",\n",
    "    \"     .when(col(\\\"weathercode\\\").isin([1, 2, 3]), \\\"Partly cloudy\\\")\\n\",\n",
    "    \"     .when(col(\\\"weathercode\\\").isin([45, 48]), \\\"Fog\\\")\\n\",\n",
    "    \"     .when(col(\\\"weathercode\\\").isin([51, 53, 55]), \\\"Drizzle\\\")\\n\",\n",
    "    \"     .when(col(\\\"weathercode\\\").isin([56, 57]), \\\"Freezing drizzle\\\")\\n\",\n",
    "    \"     .when(col(\\\"weathercode\\\").isin([61, 63, 65]), \\\"Rain\\\")\\n\",\n",
    "    \"     .when(col(\\\"weathercode\\\").isin([66, 67]), \\\"Freezing rain\\\")\\n\",\n",
    "    \"     .when(col(\\\"weathercode\\\").isin([71, 73, 75]), \\\"Snow fall\\\")\\n\",\n",
    "    \"     .when(col(\\\"weathercode\\\").isin([77]), \\\"Snow grains\\\")\\n\",\n",
    "    \"     .when(col(\\\"weathercode\\\").isin([80, 81, 82]), \\\"Rain showers\\\")\\n\",\n",
    "    \"     .when(col(\\\"weathercode\\\").isin([85, 86]), \\\"Snow showers\\\")\\n\",\n",
    "    \"     .when(col(\\\"weathercode\\\") == 95, \\\"Thunderstorm\\\")\\n\",\n",
    "    \"     .when(col(\\\"weathercode\\\").isin([96, 99]), \\\"Thunderstorm with hail\\\")\\n\",\n",
    "    \"     .otherwise(\\\"Unknown\\\")\\n\",\n",
    "    \").select(\\n\",\n",
    "    \"    \\\"city\\\",\\n\",\n",
    "    \"    \\\"processed_timestamp\\\",\\n\",\n",
    "    \"    \\\"temperature\\\",\\n\",\n",
    "    \"    \\\"windspeed\\\",\\n\",\n",
    "    \"    \\\"winddirection\\\",\\n\",\n",
    "    \"    \\\"is_day\\\",\\n\",\n",
    "    \"    \\\"weather_condition\\\",\\n\",\n",
    "    \"    \\\"weathercode\\\",\\n\",\n",
    "    \"    \\\"latitude\\\",\\n\",\n",
    "    \"    \\\"longitude\\\"\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"transformed_df.display()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create temp view for next task\\n\",\n",
    "    \"transformed_df.write.mode(\\\"overwrite\\\").saveAsTable(\\\"temp_weather_transformed\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# COMMAND ----------\\n\",\n",
    "    \"dbutils.notebook.exit(\\\"Data transformation completed successfully\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"metadata\": {\n",
    "    \"application/vnd.databricks.v1+cell\": {\n",
    "     \"cellMetadata\": {},\n",
    "     \"inputWidgets\": {},\n",
    "     \"nuid\": \"1666eb4b-7c79-48c1-971f-390664e9da7c\",\n",
    "     \"showTitle\": false,\n",
    "     \"tableResultSettingsMap\": {},\n",
    "     \"title\": \"\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Databricks notebook source\\n\",\n",
    "    \"from datetime import datetime\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Read transformed data\\n\",\n",
    "    \"transformed_df = spark.table(\\\"temp_weather_transformed\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Define output path with timestamp\\n\",\n",
    "    \"output_path = f\\\"/mnt/weather_data/hanoi/{datetime.now().strftime('%Y/%m/%d/%H%M')}\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save as Parquet\\n\",\n",
    "    \"transformed_df.write.parquet(output_path, mode=\\\"overwrite\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# COMMAND ----------\\n\",\n",
    "    \"dbutils.notebook.exit(f\\\"Weather data saved to DBFS at {output_path}\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"application/vnd.databricks.v1+notebook\": {\n",
    "   \"computePreferences\": null,\n",
    "   \"dashboards\": [],\n",
    "   \"environmentMetadata\": {\n",
    "    \"base_environment\": \"\",\n",
    "    \"environment_version\": \"2\"\n",
    "   },\n",
    "   \"inputWidgetPreferences\": null,\n",
    "   \"language\": \"python\",\n",
    "   \"notebookMetadata\": {\n",
    "    \"pythonIndentUnit\": 4\n",
    "   },\n",
    "   \"notebookName\": \"Deploy Workloads with Databricks Workflows\",\n",
    "   \"widgets\": {}\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 0\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
